import streamlit as st
import whisper
from pydub import AudioSegment
import tempfile
import os
from datetime import datetime, timedelta
import pandas as pd
import plotly.graph_objects as go
from collections import Counter
import json
import re

# Cáº¥u hÃ¬nh trang
st.set_page_config(
    page_title="PhÃ¢n tÃ­ch PhÃ¡t Ã‚m Tiáº¿ng Anh",
    page_icon="ğŸ¤",
    layout="wide",
)

# CSS tÃ¹y chá»‰nh
st.markdown(
    """
<style>
    .stButton>button {
        width: 100%;
    }
    .score-excellent {
        color: #00c853;
        font-size: 48px;
        font-weight: bold;
    }
    .score-good {
        color: #ffd600;
        font-size: 48px;
        font-weight: bold;
    }
    .score-average {
        color: #ff9800;
        font-size: 48px;
        font-weight: bold;
    }
    .score-poor {
        color: #ff5252;
        font-size: 48px;
        font-weight: bold;
    }
    .stat-box {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
    }
    .streak-badge {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 15px;
        border-radius: 10px;
        text-align: center;
        font-size: 24px;
        font-weight: bold;
    }
</style>
""",
    unsafe_allow_html=True,
)

# Khá»Ÿi táº¡o session state
if "history" not in st.session_state:
    st.session_state.history = []

if "model" not in st.session_state:
    st.session_state.model = None

if "user_name" not in st.session_state:
    st.session_state.user_name = "Há»c viÃªn"

if "daily_goal" not in st.session_state:
    st.session_state.daily_goal = 10

if "model_size" not in st.session_state:
    st.session_state.model_size = "base"


@st.cache_resource
def load_whisper_model(model_size="base"):
    """Load mÃ´ hÃ¬nh Whisper (chá»‰ load 1 láº§n)"""
    try:
        model = whisper.load_model(model_size)
        return model
    except Exception as e:
        st.error(f"Lá»—i khi load Whisper model: {e}")
        return None


# Tá»± Ä‘á»™ng load model láº§n Ä‘áº§u
if st.session_state.model is None:
    st.session_state.model = load_whisper_model("base")


def convert_audio_to_wav(audio_file):
    """Chuyá»ƒn Ä‘á»•i file audio vá» Ä‘á»‹nh dáº¡ng WAV chuáº©n"""
    try:
        audio = AudioSegment.from_file(audio_file)
        audio = audio.set_channels(1)
        audio = audio.set_frame_rate(16000)
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        audio.export(temp_file.name, format="wav")
        return temp_file.name
    except Exception as e:
        st.error(f"Lá»—i chuyá»ƒn Ä‘á»•i audio: {e}")
        return None


def transcribe_audio(audio_path, model):
    """Nháº­n dáº¡ng giá»ng nÃ³i tá»« file audio báº±ng Whisper"""
    try:
        result = model.transcribe(audio_path, language="en")
        return result["text"].strip()
    except Exception as e:
        st.error(f"Lá»—i nháº­n dáº¡ng giá»ng nÃ³i: {e}")
        return None


def check_grammar_basic(text):
    """
    Kiá»ƒm tra lá»—i ngá»¯ phÃ¡p cÆ¡ báº£n (mÃ´ phá»ng)
    Tráº£ vá» Ä‘iá»ƒm tá»« 0-2
    """
    words = text.lower().split()
    errors = []
    score = 2.0

    # Kiá»ƒm tra Subject-Verb Agreement cÆ¡ báº£n
    common_errors = [
        ("i is", "i am"),
        ("he are", "he is"),
        ("she are", "she is"),
        ("they is", "they are"),
        ("we is", "we are"),
        ("i does", "i do"),
        ("he do", "he does"),
        ("she do", "she does"),
    ]

    text_lower = text.lower()
    for wrong, correct in common_errors:
        if wrong in text_lower:
            errors.append(f"Lá»—i S-V: '{wrong}' â†’ '{correct}'")
            score -= 0.3

    # Kiá»ƒm tra thiáº¿u Ä‘á»™ng tá»« (cÃ¢u khÃ´ng cÃ³ Ä‘á»™ng tá»« phá»• biáº¿n)
    sentences = re.split(r"[.!?]", text)
    basic_verbs = [
        "is",
        "are",
        "am",
        "was",
        "were",
        "have",
        "has",
        "had",
        "do",
        "does",
        "did",
        "can",
        "could",
        "will",
        "would",
        "should",
        "go",
        "get",
        "make",
        "take",
        "see",
        "know",
    ]

    for sent in sentences:
        sent_words = sent.lower().split()
        if len(sent_words) > 3:  # CÃ¢u Ä‘á»§ dÃ i
            has_verb = any(verb in sent_words for verb in basic_verbs)
            if not has_verb:
                score -= 0.2

    return max(score, 0), errors


def check_fluency(text):
    """
    ÄÃ¡nh giÃ¡ Ä‘á»™ trÃ´i cháº£y vÃ  tá»± nhiÃªn (dá»±a trÃªn cáº¥u trÃºc cÃ¢u)
    Tráº£ vá» Ä‘iá»ƒm tá»« 0-2
    """
    words = text.split()
    word_count = len(words)

    if word_count == 0:
        return 0, ["KhÃ´ng cÃ³ ná»™i dung"]

    # Äáº¿m sá»‘ cÃ¢u
    sentences = re.split(r"[.!?]+", text)
    sentences = [s.strip() for s in sentences if s.strip()]
    sentence_count = len(sentences)

    # TÃ­nh Ä‘á»™ dÃ i cÃ¢u trung bÃ¬nh
    avg_sentence_length = word_count / max(sentence_count, 1)

    score = 1.5  # Äiá»ƒm cÆ¡ báº£n
    issues = []

    # Äá»™ dÃ i bÃ i nÃ³i
    if word_count >= 40:
        score += 0.3
    elif word_count < 20:
        score -= 0.3
        issues.append("BÃ i nÃ³i quÃ¡ ngáº¯n")

    # Äá»™ dÃ i cÃ¢u (cÃ¢u quÃ¡ ngáº¯n hoáº·c quÃ¡ dÃ i Ä‘á»u khÃ´ng tá»‘t)
    if 5 <= avg_sentence_length <= 15:
        score += 0.2
    elif avg_sentence_length < 3:
        issues.append("CÃ¢u quÃ¡ ngáº¯n, thiáº¿u tá»± nhiÃªn")
        score -= 0.2

    return max(min(score, 2.0), 0), issues


def check_vocabulary(text):
    """
    ÄÃ¡nh giÃ¡ tá»« vá»±ng (Ä‘a dáº¡ng vÃ  phÃ¹ há»£p chá»§ Ä‘á»)
    Tráº£ vá» Ä‘iá»ƒm tá»« 0-2
    """
    words = text.lower().split()
    words_clean = [re.sub(r"[^a-z]", "", w) for w in words]
    words_clean = [w for w in words_clean if len(w) > 2]

    if len(words_clean) == 0:
        return 0, ["KhÃ´ng cÃ³ tá»« vá»±ng"]

    # TÃ­nh Ä‘á»™ Ä‘a dáº¡ng tá»« vá»±ng
    unique_words = set(words_clean)
    vocab_diversity = len(unique_words) / len(words_clean)

    # Äáº¿m tá»« phá»©c táº¡p (>= 6 kÃ½ tá»±)
    complex_words = [w for w in words_clean if len(w) >= 6]
    complex_ratio = len(complex_words) / len(words_clean)

    score = 1.0  # Äiá»ƒm cÆ¡ báº£n
    issues = []

    # Äiá»ƒm tá»« Ä‘á»™ Ä‘a dáº¡ng
    if vocab_diversity >= 0.6:
        score += 0.5
    elif vocab_diversity < 0.4:
        issues.append("Tá»« vá»±ng bá»‹ láº·p láº¡i nhiá»u")
        score -= 0.2

    # Äiá»ƒm tá»« Ä‘á»™ phá»©c táº¡p
    if complex_ratio >= 0.2:
        score += 0.5
    elif complex_ratio < 0.1:
        issues.append("NÃªn sá»­ dá»¥ng tá»« vá»±ng Ä‘a dáº¡ng hÆ¡n")
        score -= 0.2

    return max(min(score, 2.0), 0), issues


def check_pronunciation(text, reference_text=None):
    """
    ÄÃ¡nh giÃ¡ phÃ¡t Ã¢m dá»±a trÃªn:
    1. Äá»™ CHÃNH XÃC vÃ  Máº CH Láº C cá»§a transcription (náº¿u khÃ´ng cÃ³ reference)
    2. Äá»™ TÆ¯Æ NG Äá»’NG vá»›i cÃ¢u gá»‘c (náº¿u cÃ³ reference)
    Tráº£ vá» Ä‘iá»ƒm tá»« 0-2 vÃ  feedback chi tiáº¿t
    """
    words = text.split()
    word_count = len(words)

    if word_count == 0:
        return 0, ["âš ï¸ KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c ná»™i dung"]

    # ==== PHáº¦N 1: Náº¾U CÃ“ REFERENCE TEXT - SO SÃNH TRá»°C TIáº¾P ====
    if reference_text and reference_text.strip():
        return check_pronunciation_with_reference(text, reference_text)

    # ==== PHáº¦N 2: Náº¾U KHÃ”NG CÃ“ REFERENCE - ÄÃNH GIÃ Dá»°A TRÃŠN CHáº¤T LÆ¯á»¢NG ====
    # CÃ¡c pattern bÃ¡o hiá»‡u phÃ¡t Ã¢m KÃ‰M (Whisper nháº­n dáº¡ng sai)
    error_indicators = {
        # Tá»« vÃ´ nghÄ©a / ngáº«u nhiÃªn
        "nonsense_words": [
            "hver",
            "ung",
            "hver",
            "isch",
            "artstrom",
            "justarta",
            "matery",
            "hver",
            "Ø§Ù„Øª",
            "Ø§Ù„",
        ],
        # Pattern láº·p láº¡i báº¥t thÆ°á»ng
        "repetitive": ["me me", "I I", "you you", "the the the"],
        # Tá»« quÃ¡ ngáº¯n khÃ´ng rÃµ nghÄ©a
        "unclear_short": ["i", "a", "o", "u", "e"],  # ÄÆ¡n láº», khÃ´ng cÃ³ ngá»¯ cáº£nh
    }

    # PhÃ¢n tÃ­ch cháº¥t lÆ°á»£ng transcription
    issues = []
    penalty = 0.0

    # 1. Kiá»ƒm tra tá»« vÃ´ nghÄ©a
    nonsense_count = 0
    nonsense_found = []
    text_lower = text.lower()

    for nonsense in error_indicators["nonsense_words"]:
        if nonsense in text_lower:
            nonsense_count += 1
            nonsense_found.append(nonsense)

    if nonsense_count > 0:
        penalty += 0.3 * min(nonsense_count, 3)  # Max -0.9
        issues.append(f"âš ï¸ PhÃ¡t hiá»‡n {nonsense_count} tá»« khÃ´ng rÃµ nghÄ©a")

    # 2. Kiá»ƒm tra pattern láº·p láº¡i báº¥t thÆ°á»ng
    repetition_count = 0
    for pattern in error_indicators["repetitive"]:
        if pattern in text_lower:
            repetition_count += 1

    if repetition_count > 0:
        penalty += 0.2 * repetition_count
        issues.append("âš ï¸ PhÃ¡t hiá»‡n pattern láº·p tá»« báº¥t thÆ°á»ng")

    # 3. Kiá»ƒm tra tá»· lá»‡ tá»« quÃ¡ ngáº¯n (< 3 kÃ½ tá»±) - dáº¥u hiá»‡u nÃ³i ngáº¯t quÃ£ng
    short_words = [w for w in words if len(re.sub(r"[^a-zA-Z]", "", w)) < 3]
    short_ratio = len(short_words) / word_count

    if short_ratio > 0.5:  # QuÃ¡ 50% tá»« ngáº¯n
        penalty += 0.3
        issues.append(
            f"âš ï¸ QuÃ¡ nhiá»u tá»« ngáº¯n ({short_ratio*100:.0f}%) - phÃ¡t Ã¢m cÃ³ thá»ƒ khÃ´ng rÃµ"
        )

    # 4. Kiá»ƒm tra Ä‘á»™ dÃ i trung bÃ¬nh cá»§a tá»« (tá»« quÃ¡ ngáº¯n = phÃ¡t Ã¢m khÃ´ng rÃµ)
    avg_word_length = sum(len(re.sub(r"[^a-zA-Z]", "", w)) for w in words) / word_count

    if avg_word_length < 3.0:
        penalty += 0.2
        issues.append(f"âš ï¸ Tá»« trung bÃ¬nh quÃ¡ ngáº¯n ({avg_word_length:.1f} kÃ½ tá»±)")

    # 5. Kiá»ƒm tra tÃ­nh máº¡ch láº¡c cÃ¢u (cÃ³ Ä‘á»™ng tá»«, danh tá»« cÆ¡ báº£n)
    has_basic_structure = any(
        word in text_lower
        for word in ["is", "am", "are", "have", "can", "my", "i", "you", "we"]
    )

    if not has_basic_structure:
        penalty += 0.3
        issues.append("âš ï¸ Thiáº¿u cáº¥u trÃºc cÃ¢u cÆ¡ báº£n")

    # 6. Kiá»ƒm tra tá»· lá»‡ kÃ½ tá»± sá»‘/Ä‘áº·c biá»‡t (dáº¥u hiá»‡u Whisper khÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c)
    special_char_count = len(re.findall(r"[^a-zA-Z0-9\s\.\,\!\?]", text))
    if special_char_count > word_count * 0.1:  # QuÃ¡ 10%
        penalty += 0.2
        issues.append("âš ï¸ Chá»©a nhiá»u kÃ½ tá»± Ä‘áº·c biá»‡t (dáº¥u hiá»‡u khÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c)")

    # TÃ­nh Ä‘iá»ƒm pronunciation (2.0 - penalty)
    score = max(2.0 - penalty, 0.0)

    # Táº¡o feedback chi tiáº¿t
    feedback = []
    feedback.append(f"**ğŸ“Š PhÃ¢n tÃ­ch Pronunciation:**")
    feedback.append(f"â€¢ Tá»•ng sá»‘ tá»«: **{word_count}** tá»«")
    feedback.append(f"â€¢ Äá»™ dÃ i tá»« TB: **{avg_word_length:.1f}** kÃ½ tá»±")
    feedback.append(f"â€¢ Tá»· lá»‡ tá»« ngáº¯n: **{short_ratio*100:.0f}%**")
    feedback.append("")

    # Hiá»ƒn thá»‹ cÃ¡c váº¥n Ä‘á» phÃ¡t hiá»‡n Ä‘Æ°á»£c
    if issues:
        feedback.append("**ğŸ” Váº¥n Ä‘á» phÃ¡t hiá»‡n:**")
        for issue in issues:
            feedback.append(f"â€¢ {issue}")
        feedback.append("")

        if nonsense_found:
            feedback.append("**âŒ Tá»« khÃ´ng rÃµ nghÄ©a:**")
            feedback.append(f"â€¢ {', '.join(nonsense_found[:5])}")
            feedback.append("")

    # ÄÃ¡nh giÃ¡ tá»•ng quan
    if score >= 1.8:
        feedback.append(
            "**âœ… PhÃ¡t Ã¢m xuáº¥t sáº¯c!** Whisper nháº­n dáº¡ng ráº¥t tá»‘t, giá»ng nÃ³i rÃµ rÃ ng."
        )
    elif score >= 1.5:
        feedback.append(
            "**âœ… PhÃ¡t Ã¢m tá»‘t!** Whisper nháº­n dáº¡ng tá»‘t, chá»‰ má»™t vÃ i chá»— cáº§n cáº£i thiá»‡n."
        )
    elif score >= 1.2:
        feedback.append(
            "**ğŸ“Œ PhÃ¡t Ã¢m khÃ¡.** Má»™t sá»‘ tá»« chÆ°a rÃµ, cáº§n phÃ¡t Ã¢m rÃµ rÃ ng hÆ¡n."
        )
    elif score >= 0.8:
        feedback.append(
            "**âš ï¸ PhÃ¡t Ã¢m cáº§n cáº£i thiá»‡n.** Nhiá»u tá»« Whisper nháº­n dáº¡ng khÃ´ng chÃ­nh xÃ¡c."
        )
    else:
        feedback.append(
            "**âŒ PhÃ¡t Ã¢m kÃ©m.** Whisper gáº·p khÃ³ khÄƒn nháº­n dáº¡ng, cáº§n luyá»‡n táº­p nhiá»u."
        )

    # Gá»£i Ã½ cáº£i thiá»‡n
    if score < 1.5:
        feedback.append("")
        feedback.append("**ğŸ’¡ CÃ¡ch cáº£i thiá»‡n:**")
        feedback.append("1. **PhÃ¡t Ã¢m rÃµ tá»«ng tá»«:** NÃ³i cháº­m, rÃµ rÃ ng")
        feedback.append("2. **KhÃ´ng nÃ³i ngáº¯t quÃ£ng:** NÃ³i trá»n cÃ¢u, khÃ´ng dá»«ng giá»¯a tá»«")
        feedback.append("3. **Luyá»‡n Ã¢m khÃ³:** /r/, /l/, /th/, /v/, /s/")
        feedback.append(
            "4. **Ghi Ã¢m vÃ  nghe láº¡i:** So sÃ¡nh vá»›i phÃ¡t Ã¢m chuáº©n (Google Translate, Youglish)"
        )

    return round(score, 1), feedback


def check_pronunciation_with_reference(transcribed, reference):
    """
    So sÃ¡nh transcribed text vá»›i reference text Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ phÃ¡t Ã¢m
    Sá»­ dá»¥ng Word Error Rate (WER) vÃ  phÃ¢n tÃ­ch chi tiáº¿t
    """

    # Chuáº©n hÃ³a text
    def normalize(text):
        text = text.lower()
        text = re.sub(r"[^a-z\s]", "", text)  # Chá»‰ giá»¯ chá»¯ cÃ¡i vÃ  space
        return text.split()

    ref_words = normalize(reference)
    trans_words = normalize(transcribed)

    if len(ref_words) == 0:
        return 0, ["âš ï¸ CÃ¢u tham chiáº¿u khÃ´ng há»£p lá»‡"]

    # TÃ­nh Word Error Rate (WER) báº±ng Levenshtein Distance
    def levenshtein_distance(s1, s2):
        if len(s1) < len(s2):
            return levenshtein_distance(s2, s1)
        if len(s2) == 0:
            return len(s1)
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        return previous_row[-1]

    # PhÃ¢n tÃ­ch chi tiáº¿t tá»«ng tá»«
    correct_words = 0
    missing_words = []
    extra_words = []

    # So sÃ¡nh tá»«ng tá»« (simple alignment)
    ref_set = set(ref_words)
    trans_set = set(trans_words)

    # Tá»« Ä‘Ãºng: cÃ³ trong cáº£ 2
    matched_ref = []
    matched_trans = []

    for word in ref_words:
        if word in trans_set and word not in matched_ref:
            correct_words += 1
            matched_ref.append(word)
            matched_trans.append(word)

    # Tá»« thiáº¿u: cÃ³ trong ref nhÆ°ng khÃ´ng khá»›p
    for word in ref_words:
        if word not in matched_ref:
            missing_words.append(word)

    # Tá»« thá»«a: cÃ³ trong trans nhÆ°ng khÃ´ng khá»›p (CHá»ˆ Äá»‚ HIá»‚N THá»Š, KHÃ”NG TRá»ª ÄIá»‚M)
    for word in trans_words:
        if word not in matched_trans and word not in ref_set:
            extra_words.append(word)

    # TÃ­nh accuracy CHá»ˆ dá»±a trÃªn tá»« ÄÃšNG vÃ  THIáº¾U (bá» qua tá»« thá»«a)
    # CÃ´ng thá»©c: Accuracy = (Tá»« Ä‘Ãºng) / (Tá»•ng tá»« gá»‘c)
    accuracy = correct_words / len(ref_words)
    accuracy_percent = accuracy * 100

    # TÃ­nh lá»—i chá»‰ tá»« missing words
    error_rate = len(missing_words) / len(ref_words)

    # TÃ­nh Ä‘iá»ƒm pronunciation dá»±a trÃªn accuracy
    if accuracy >= 0.95:
        score = 2.0
        grade = "Xuáº¥t sáº¯c"
        emoji = "ğŸŸ¢"
    elif accuracy >= 0.90:
        score = 1.8
        grade = "Ráº¥t tá»‘t"
        emoji = "ğŸŸ¢"
    elif accuracy >= 0.80:
        score = 1.5
        grade = "KhÃ¡ tá»‘t"
        emoji = "ğŸŸ¡"
    elif accuracy >= 0.70:
        score = 1.2
        grade = "Trung bÃ¬nh khÃ¡"
        emoji = "ğŸŸ¡"
    elif accuracy >= 0.60:
        score = 0.9
        grade = "Trung bÃ¬nh"
        emoji = "ğŸŸ "
    elif accuracy >= 0.50:
        score = 0.6
        grade = "Yáº¿u"
        emoji = "ğŸŸ "
    else:
        score = 0.3
        grade = "KÃ©m"
        emoji = "ğŸ”´"

    # Táº¡o feedback chi tiáº¿t
    feedback = []
    feedback.append(f"**ğŸ“Š PhÃ¢n tÃ­ch So sÃ¡nh vá»›i CÃ¢u Gá»‘c:**")
    feedback.append(f"â€¢ **Äá»™ chÃ­nh xÃ¡c: {emoji} {accuracy_percent:.1f}%** ({grade})")
    feedback.append(f"â€¢ CÃ¢u gá»‘c: **{len(ref_words)}** tá»«")
    feedback.append(f"â€¢ Báº¡n nÃ³i: **{len(trans_words)}** tá»«")
    feedback.append(f"â€¢ Tá»« phÃ¡t Ã¢m Ä‘Ãºng: **{correct_words}/{len(ref_words)}** tá»«")
    feedback.append(f"â€¢ Tá»« thiáº¿u/sai: **{len(missing_words)}** tá»«")
    if extra_words:
        feedback.append(
            f"â€¢ Tá»« má»Ÿ rá»™ng thÃªm: **{len(extra_words)}** tá»« *(khÃ´ng trá»« Ä‘iá»ƒm)*"
        )
    feedback.append("")

    # Hiá»ƒn thá»‹ tá»« thiáº¿u chi tiáº¿t
    if missing_words:
        feedback.append(f"**âŒ Tá»« THIáº¾U/SAI ({len(missing_words)} tá»«):**")
        missing_unique = list(set(missing_words))[:15]
        feedback.append(f"â€¢ {', '.join(missing_unique)}")
        feedback.append("")

    if extra_words:
        feedback.append(f"**â• Tá»« Má» Rá»˜NG THÃŠM ({len(extra_words)} tá»«):**")
        extra_unique = list(set(extra_words))[:15]
        feedback.append(f"â€¢ {', '.join(extra_unique)}")
        feedback.append(f"â€¢ *(KhÃ´ng bá»‹ trá»« Ä‘iá»ƒm - Khuyáº¿n khÃ­ch má»Ÿ rá»™ng Ã½!)*")
        feedback.append("")

    # ÄÃ¡nh giÃ¡ tá»•ng quan
    if accuracy >= 0.90:
        feedback.append(
            "**âœ… Xuáº¥t sáº¯c!** PhÃ¡t Ã¢m ráº¥t chuáº©n, pháº§n lá»›n tá»« trong cÃ¢u gá»‘c Ä‘á»u Ä‘Ãºng."
        )
    elif accuracy >= 0.80:
        feedback.append(
            "**âœ… Ráº¥t tá»‘t!** Pháº§n lá»›n tá»« phÃ¡t Ã¢m chuáº©n, chá»‰ thiáº¿u/sai má»™t vÃ i tá»«."
        )
    elif accuracy >= 0.70:
        feedback.append("**ğŸ“Œ KhÃ¡ tá»‘t.** Má»™t sá»‘ tá»« trong cÃ¢u gá»‘c cáº§n cáº£i thiá»‡n.")
    elif accuracy >= 0.60:
        feedback.append("**âš ï¸ Trung bÃ¬nh.** Nhiá»u tá»« trong cÃ¢u gá»‘c bá»‹ thiáº¿u/sai.")
    else:
        feedback.append(
            "**âŒ Cáº§n cáº£i thiá»‡n.** Pháº§n lá»›n tá»« trong cÃ¢u gá»‘c chÆ°a phÃ¡t Ã¢m Ä‘Ãºng."
        )

    # Gá»£i Ã½ cáº£i thiá»‡n
    if accuracy < 0.85:
        feedback.append("")
        feedback.append("**ğŸ’¡ Gá»£i Ã½ cáº£i thiá»‡n:**")
        feedback.append("1. **Táº­p trung vÃ o tá»« THIáº¾U/SAI** á»Ÿ trÃªn")
        feedback.append("2. **Äá»c cháº­m tá»«ng tá»«** trong cÃ¢u gá»‘c")
        feedback.append("3. **Nghe vÃ  nháº¯c láº¡i** nhiá»u láº§n")
        feedback.append("4. **So sÃ¡nh ghi Ã¢m** cá»§a báº¡n vá»›i phÃ¡t Ã¢m chuáº©n")

    if extra_words and accuracy >= 0.75:
        feedback.append("")
        feedback.append("**ğŸŒŸ Äiá»ƒm cá»™ng:**")
        feedback.append("â€¢ Báº¡n Ä‘Ã£ má»Ÿ rá»™ng Ã½ ráº¥t tá»‘t! Tiáº¿p tá»¥c phÃ¡t triá»ƒn ká»¹ nÄƒng nÃ y!")

    return round(score, 1), feedback


def check_communication(text):
    """
    ÄÃ¡nh giÃ¡ kháº£ nÄƒng truyá»n Ä‘áº¡t Ã½ (cÃ³ tráº£ lá»i Ä‘Ãºng cÃ¢u há»i, logic, rÃµ rÃ ng)
    Tráº£ vá» Ä‘iá»ƒm tá»« 0-2
    """
    words = text.lower().split()
    word_count = len(words)

    score = 1.0  # Äiá»ƒm cÆ¡ báº£n
    issues = []

    # Kiá»ƒm tra Ä‘á»™ dÃ i (cÃ³ Ä‘á»§ ná»™i dung khÃ´ng)
    if word_count >= 30:
        score += 0.5
    elif word_count < 15:
        score -= 0.3
        issues.append("CÃ¢u tráº£ lá»i quÃ¡ ngáº¯n, thiáº¿u chi tiáº¿t")

    # Kiá»ƒm tra cÃ³ tá»« ná»‘i (because, and, so, but) - thá»ƒ hiá»‡n logic
    connectors = ["because", "and", "so", "but", "also", "however", "therefore"]
    has_connector = any(conn in words for conn in connectors)
    if has_connector:
        score += 0.3
    else:
        issues.append("NÃªn dÃ¹ng tá»« ná»‘i Ä‘á»ƒ liÃªn káº¿t Ã½")

    # Kiá»ƒm tra cÃ³ cÃ¢u giá»›i thiá»‡u (my name, i am, i like, my favorite)
    intro_phrases = ["my name", "i am", "my favorite", "i like", "i love"]
    has_intro = any(phrase in text.lower() for phrase in intro_phrases)
    if has_intro:
        score += 0.2

    return max(min(score, 2.0), 0), issues


def analyze_speech(transcribed_text, audio_path=None, reference_text=None):
    """
    PhÃ¢n tÃ­ch bÃ i nÃ³i theo 5 tiÃªu chÃ­ (má»—i tiÃªu chÃ­ /2 Ä‘iá»ƒm, tá»•ng /10)
    """
    if not transcribed_text or len(transcribed_text.strip()) == 0:
        return 0, ["âš ï¸ KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c ná»™i dung. Vui lÃ²ng thá»­ láº¡i."], {}

    # Cháº¥m tá»«ng tiÃªu chÃ­
    pronunciation_score, pronunciation_issues = check_pronunciation(
        transcribed_text, reference_text
    )
    fluency_score, fluency_issues = check_fluency(transcribed_text)
    grammar_score, grammar_issues = check_grammar_basic(transcribed_text)
    vocabulary_score, vocabulary_issues = check_vocabulary(transcribed_text)
    communication_score, communication_issues = check_communication(transcribed_text)

    # Tá»•ng Ä‘iá»ƒm /10
    total_score = (
        pronunciation_score
        + fluency_score
        + grammar_score
        + vocabulary_score
        + communication_score
    )

    # Chuyá»ƒn sang thang Ä‘iá»ƒm 100
    final_score_100 = (total_score / 10) * 100

    # Táº¡o breakdown chi tiáº¿t
    breakdown = {
        "Pronunciation": pronunciation_score,
        "Fluency": fluency_score,
        "Grammar": grammar_score,
        "Vocabulary": vocabulary_score,
        "Communication": communication_score,
        "Total": total_score,
    }

    # Táº¡o feedback chi tiáº¿t
    feedback = []

    feedback.append(
        f"ğŸ“Š **Tá»”NG ÄIá»‚M: {total_score:.1f}/10** ({final_score_100:.0f}/100)"
    )
    feedback.append("---")

    # 1. Pronunciation
    feedback.append(f"ğŸ—£ï¸ **1. Pronunciation (PhÃ¡t Ã¢m): {pronunciation_score:.1f}/2**")
    feedback.append("")
    if pronunciation_issues:
        for issue in pronunciation_issues:
            feedback.append(f"{issue}")
    feedback.append("")

    # 2. Fluency
    feedback.append(f"ğŸµ **2. Fluency (Äá»™ trÃ´i cháº£y): {fluency_score:.1f}/2**")
    if fluency_issues:
        for issue in fluency_issues:
            feedback.append(f"   â€¢ {issue}")
    else:
        feedback.append("   â€¢ NÃ³i khÃ¡ tá»± nhiÃªn vÃ  máº¡ch láº¡c")
    feedback.append("")

    # 3. Grammar
    feedback.append(f"ğŸ“ **3. Grammar (Ngá»¯ phÃ¡p): {grammar_score:.1f}/2**")
    if grammar_issues:
        for issue in grammar_issues:
            feedback.append(f"   â€¢ {issue}")
    else:
        feedback.append("   â€¢ Ngá»¯ phÃ¡p chÃ­nh xÃ¡c")
    feedback.append("")

    # 4. Vocabulary
    feedback.append(f"ğŸ“š **4. Vocabulary (Tá»« vá»±ng): {vocabulary_score:.1f}/2**")
    if vocabulary_issues:
        for issue in vocabulary_issues:
            feedback.append(f"   â€¢ {issue}")
    else:
        feedback.append("   â€¢ Tá»« vá»±ng Ä‘a dáº¡ng vÃ  phÃ¹ há»£p")
    feedback.append("")

    # 5. Communication
    feedback.append(f"ğŸ’¬ **5. Communication (Giao tiáº¿p): {communication_score:.1f}/2**")
    if communication_issues:
        for issue in communication_issues:
            feedback.append(f"   â€¢ {issue}")
    else:
        feedback.append("   â€¢ Truyá»n Ä‘áº¡t Ã½ rÃµ rÃ ng vÃ  logic")

    return round(final_score_100, 1), feedback, breakdown


def save_result_to_history(topic, transcribed, score, wrong_words, breakdown=None):
    """LÆ°u káº¿t quáº£ vÃ o lá»‹ch sá»­"""
    result = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "date": datetime.now().strftime("%Y-%m-%d"),
        "time": datetime.now().strftime("%H:%M:%S"),
        "reference": topic,
        "transcribed": transcribed,
        "score": score,
        "wrong_words": wrong_words,
        "word_count": len(transcribed.split()),
        "user": st.session_state.user_name,
        "mode": "BÃ i nÃ³i tá»± do",
        "breakdown": breakdown if breakdown else {},
    }
    st.session_state.history.append(result)


def export_history_to_csv():
    """Xuáº¥t lá»‹ch sá»­ ra CSV"""
    if not st.session_state.history:
        return None

    df = pd.DataFrame(st.session_state.history)
    return df.to_csv(index=False).encode("utf-8")


def export_history_to_json():
    """Xuáº¥t lá»‹ch sá»­ ra JSON (Ä‘á»ƒ backup)"""
    if not st.session_state.history:
        return None

    data = {
        "export_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "user_name": st.session_state.user_name,
        "history": st.session_state.history,
    }
    return json.dumps(data, indent=2, ensure_ascii=False).encode("utf-8")


def import_history_from_json(json_file):
    """Nháº­p lá»‹ch sá»­ tá»« JSON"""
    try:
        data = json.loads(json_file.read())
        st.session_state.history = data.get("history", [])
        return True
    except Exception as e:
        st.error(f"Lá»—i import: {e}")
        return False


def get_statistics():
    """TÃ­nh toÃ¡n thá»‘ng kÃª"""
    if not st.session_state.history:
        return None

    df = pd.DataFrame(st.session_state.history)

    stats = {
        "total_attempts": len(df),
        "avg_score": df["score"].mean(),
        "max_score": df["score"].max(),
        "min_score": df["score"].min(),
        "today_attempts": len(df[df["date"] == datetime.now().strftime("%Y-%m-%d")]),
        "excellent_count": len(df[df["score"] >= 90]),
        "good_count": len(df[(df["score"] >= 75) & (df["score"] < 90)]),
        "average_count": len(df[(df["score"] >= 60) & (df["score"] < 75)]),
        "poor_count": len(df[df["score"] < 60]),
    }

    return stats


def calculate_streak():
    """TÃ­nh chuá»—i ngÃ y luyá»‡n táº­p liÃªn tá»¥c"""
    if not st.session_state.history:
        return 0

    df = pd.DataFrame(st.session_state.history)
    unique_dates = sorted(df["date"].unique(), reverse=True)

    if not unique_dates:
        return 0

    today = datetime.now().strftime("%Y-%m-%d")

    if unique_dates[0] != today:
        yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
        if unique_dates[0] != yesterday:
            return 0

    streak = 1
    for i in range(len(unique_dates) - 1):
        current = datetime.strptime(unique_dates[i], "%Y-%m-%d")
        next_date = datetime.strptime(unique_dates[i + 1], "%Y-%m-%d")

        if (current - next_date).days == 1:
            streak += 1
        else:
            break

    return streak


def create_progress_chart():
    """Táº¡o biá»ƒu Ä‘á»“ tiáº¿n Ä‘á»™"""
    if not st.session_state.history:
        return None

    df = pd.DataFrame(st.session_state.history)
    df["attempt_number"] = range(1, len(df) + 1)

    fig = go.Figure()

    fig.add_trace(
        go.Scatter(
            x=df["attempt_number"],
            y=df["score"],
            mode="lines+markers",
            name="Äiá»ƒm sá»‘",
            line=dict(color="#1f77b4", width=3),
            marker=dict(size=8),
        )
    )

    fig.add_hline(
        y=90, line_dash="dash", line_color="green", annotation_text="Xuáº¥t sáº¯c (90)"
    )
    fig.add_hline(
        y=75, line_dash="dash", line_color="orange", annotation_text="KhÃ¡ (75)"
    )
    fig.add_hline(
        y=60, line_dash="dash", line_color="red", annotation_text="Trung bÃ¬nh (60)"
    )

    fig.update_layout(
        title="ğŸ“ˆ Biá»ƒu Ä‘á»“ tiáº¿n Ä‘á»™ há»c táº­p",
        xaxis_title="Láº§n cháº¥m",
        yaxis_title="Äiá»ƒm sá»‘",
        yaxis_range=[0, 105],
        hovermode="x unified",
    )

    return fig


def create_score_distribution():
    """Táº¡o biá»ƒu Ä‘á»“ phÃ¢n bá»‘ Ä‘iá»ƒm"""
    if not st.session_state.history:
        return None

    df = pd.DataFrame(st.session_state.history)

    fig = go.Figure()

    fig.add_trace(
        go.Histogram(x=df["score"], nbinsx=20, marker_color="#1f77b4", opacity=0.7)
    )

    fig.update_layout(
        title="ğŸ“Š PhÃ¢n bá»‘ Ä‘iá»ƒm sá»‘",
        xaxis_title="Äiá»ƒm sá»‘",
        yaxis_title="Sá»‘ láº§n",
        bargap=0.1,
    )

    return fig


def create_weekly_chart():
    """Biá»ƒu Ä‘á»“ theo tuáº§n"""
    if not st.session_state.history:
        return None

    df = pd.DataFrame(st.session_state.history)
    df["date"] = pd.to_datetime(df["date"])

    end_date = datetime.now()
    start_date = end_date - timedelta(days=6)

    date_range = pd.date_range(start=start_date, end=end_date)
    daily_stats = []

    for date in date_range:
        date_str = date.strftime("%Y-%m-%d")
        day_data = df[df["date"] == date_str]

        if len(day_data) > 0:
            daily_stats.append(
                {
                    "date": date.strftime("%d/%m"),
                    "count": len(day_data),
                    "avg_score": day_data["score"].mean(),
                }
            )
        else:
            daily_stats.append(
                {"date": date.strftime("%d/%m"), "count": 0, "avg_score": 0}
            )

    stats_df = pd.DataFrame(daily_stats)

    fig = go.Figure()

    fig.add_trace(
        go.Bar(
            x=stats_df["date"],
            y=stats_df["count"],
            name="Sá»‘ láº§n luyá»‡n",
            marker_color="#1f77b4",
        )
    )

    fig.update_layout(
        title="ğŸ“… Hoáº¡t Ä‘á»™ng 7 ngÃ y gáº§n nháº¥t",
        xaxis_title="NgÃ y",
        yaxis_title="Sá»‘ láº§n luyá»‡n táº­p",
    )

    return fig


# ========== GIAO DIá»†N CHÃNH ==========

# Header vá»›i tabs
tab1, tab2, tab3 = st.tabs(["ğŸ¤ PhÃ¢n tÃ­ch BÃ i nÃ³i", "ğŸ“Š Thá»‘ng kÃª", "âš™ï¸ CÃ i Ä‘áº·t"])

# TAB 1: PHÃ‚N TÃCH BÃ€I NÃ“I
with tab1:
    st.title("ğŸ¤ PHÃ‚N TÃCH PHÃT Ã‚M BÃ€I NÃ“I Tá»° DO")

    # ThÃ´ng tin ngÆ°á»i dÃ¹ng vÃ  streak
    col_info1, col_info2, col_info3, col_info4 = st.columns(4)

    with col_info1:
        st.markdown(f"**ğŸ‘¤ Há»c viÃªn:** {st.session_state.user_name}")

    with col_info2:
        streak = calculate_streak()
        if streak > 0:
            st.markdown(f"**ğŸ”¥ Streak:** {streak} ngÃ y")

    with col_info3:
        stats = get_statistics()
        if stats:
            st.markdown(
                f"**ğŸ“ˆ HÃ´m nay:** {stats['today_attempts']}/{st.session_state.daily_goal} láº§n"
            )
            progress = min(stats["today_attempts"] / st.session_state.daily_goal, 1.0)
            st.progress(progress)

    with col_info4:
        if stats:
            st.markdown(f"**â­ Äiá»ƒm TB:** {stats['avg_score']:.1f}/100")

    st.divider()

    # Pháº§n nháº­p chá»§ Ä‘á»
    st.subheader("ğŸ“ BÆ°á»›c 1: Nháº­p chá»§ Ä‘á»/Ä‘á» bÃ i")

    # THÃŠM COLUMNS
    col_topic1, col_topic2 = st.columns([2, 1])

    with col_topic1:
        topic_input = st.text_input(
            "Chá»§ Ä‘á» bÃ i nÃ³i cá»§a báº¡n:",
            value="",
            placeholder="VÃ­ dá»¥: My favorite hobby, My hometown, A memorable trip...",
            help="Nháº­p chá»§ Ä‘á» mÃ  báº¡n sáº½ nÃ³i vá»",
        )

    with col_topic2:
        use_reference = st.checkbox(
            "ğŸ“‹ CÃ³ cÃ¢u máº«u?", help="Báº­t náº¿u báº¡n cÃ³ cÃ¢u gá»‘c cáº§n Ä‘á»c theo", value=False
        )

    # THÃŠM PHáº¦N REFERENCE TEXT
    reference_text = None
    if use_reference:
        reference_text = st.text_area(
            "ğŸ“ Nháº­p cÃ¢u gá»‘c (reference):",
            value="",
            placeholder="VÃ­ dá»¥: Hello everyone, my name is Ivy. I'm a student...",
            help="Nháº­p cÃ¢u gá»‘c mÃ  báº¡n cáº§n Ä‘á»c theo",
            height=100,
        )
        if reference_text:
            st.info(f"ğŸ“Œ CÃ¢u gá»‘c: **{reference_text[:100]}...**")
    elif topic_input:
        st.info(f"ğŸ“Œ Chá»§ Ä‘á»: **{topic_input}**")

    st.divider()

    # Pháº§n ghi Ã¢m vÃ  upload
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ™ï¸ BÆ°á»›c 2a: Ghi Ã¢m trá»±c tiáº¿p")
        audio_recording = st.audio_input("Nháº¥n Ä‘á»ƒ ghi Ã¢m:")

    with col2:
        st.subheader("ğŸ“¤ BÆ°á»›c 2b: Hoáº·c upload file audio")
        uploaded_file = st.file_uploader(
            "Chá»n file audio:",
            type=["wav", "mp3", "m4a", "ogg", "flac"],
            help="Há»— trá»£ cÃ¡c Ä‘á»‹nh dáº¡ng: WAV, MP3, M4A, OGG, FLAC",
        )

    st.divider()

    # NÃºt phÃ¢n tÃ­ch
    st.subheader("ğŸ¯ BÆ°á»›c 3: PhÃ¢n tÃ­ch bÃ i nÃ³i")

    if st.button("ğŸ” PhÃ¢n tÃ­ch phÃ¡t Ã¢m", type="primary", use_container_width=True):

        if not topic_input:
            st.warning("âš ï¸ Vui lÃ²ng nháº­p chá»§ Ä‘á» bÃ i nÃ³i!")
        elif not audio_recording and not uploaded_file:
            st.error("âš ï¸ Vui lÃ²ng ghi Ã¢m hoáº·c upload file audio!")
        elif not st.session_state.model:
            st.error("âš ï¸ Model chÆ°a Ä‘Æ°á»£c load. Vui lÃ²ng load trong tab CÃ i Ä‘áº·t.")
        else:
            with st.spinner("ğŸ”„ Äang xá»­ lÃ½ Ã¢m thanh..."):
                try:
                    audio_source = uploaded_file if uploaded_file else audio_recording
                    wav_path = convert_audio_to_wav(audio_source)

                    if wav_path:
                        with st.spinner("ğŸ§ Äang nháº­n dáº¡ng giá»ng nÃ³i..."):
                            transcribed_text = transcribe_audio(
                                wav_path, st.session_state.model
                            )

                        try:
                            os.unlink(wav_path)
                        except:
                            pass

                        if transcribed_text:
                            score, feedback, breakdown = analyze_speech(
                                transcribed_text, wav_path, reference_text
                            )
                            save_result_to_history(
                                topic_input,
                                transcribed_text,
                                score,
                                feedback,
                                breakdown,
                            )

                            st.success("âœ… PhÃ¢n tÃ­ch hoÃ n táº¥t!")
                            st.balloons()

                            st.divider()

                            # Káº¿t quáº£
                            col_result1, col_result2 = st.columns(2)

                            with col_result1:
                                st.markdown("**ğŸ“Œ Chá»§ Ä‘á»:**")
                                st.info(topic_input)

                            with col_result2:
                                st.markdown("**ğŸ—£ï¸ Ná»™i dung báº¡n Ä‘Ã£ nÃ³i:**")
                                st.info(transcribed_text)

                            # Äiá»ƒm sá»‘ tá»•ng quan
                            st.markdown("### ğŸ¯ Káº¿t quáº£ cháº¥m Ä‘iá»ƒm")

                            # Hiá»ƒn thá»‹ Ä‘iá»ƒm chi tiáº¿t theo 5 tiÃªu chÃ­
                            col_breakdown = st.columns(6)

                            criteria_emojis = ["ğŸ—£ï¸", "ğŸµ", "ğŸ“", "ğŸ“š", "ğŸ’¬", "â­"]
                            criteria_names = [
                                "Pronunciation",
                                "Fluency",
                                "Grammar",
                                "Vocabulary",
                                "Communication",
                                "Total",
                            ]

                            for i, (emoji, name) in enumerate(
                                zip(criteria_emojis, criteria_names)
                            ):
                                with col_breakdown[i]:
                                    if name == "Total":
                                        st.metric(
                                            f"{emoji} {name}",
                                            f"{breakdown.get('Total', 0):.1f}/10",
                                            help="Tá»•ng Ä‘iá»ƒm",
                                        )
                                    else:
                                        st.metric(
                                            f"{emoji} {name[:4]}.",
                                            f"{breakdown.get(name, 0):.1f}/2",
                                            help=name,
                                        )

                            st.divider()

                            # Äiá»ƒm sá»‘ lá»›n vá»›i mÃ u sáº¯c (chuyá»ƒn sang thang 100 Ä‘á»ƒ hiá»ƒn thá»‹)
                            if score >= 90:
                                score_class = "score-excellent"
                                grade = "Xuáº¥t sáº¯c"
                                emoji = "ğŸŸ¢"
                            elif score >= 75:
                                score_class = "score-good"
                                grade = "KhÃ¡"
                                emoji = "ğŸŸ¡"
                            elif score >= 60:
                                score_class = "score-average"
                                grade = "Trung bÃ¬nh"
                                emoji = "ğŸŸ "
                            else:
                                score_class = "score-poor"
                                grade = "Cáº§n cáº£i thiá»‡n"
                                emoji = "ğŸ”´"

                            col_score1, col_score2 = st.columns([1, 2])

                            with col_score1:
                                st.markdown(
                                    f'<div class="{score_class}">{emoji} {score:.0f}/100</div>',
                                    unsafe_allow_html=True,
                                )

                            with col_score2:
                                st.markdown(f"### {grade}")
                                st.progress(score / 100)

                                if score >= 90:
                                    st.success(
                                        "ğŸ‰ Xuáº¥t sáº¯c! PhÃ¡t Ã¢m vÃ  ná»™i dung ráº¥t tá»‘t!"
                                    )
                                elif score >= 75:
                                    st.info(
                                        "ğŸ‘ Tá»‘t láº¯m! Tiáº¿p tá»¥c luyá»‡n táº­p Ä‘á»ƒ hoÃ n thiá»‡n hÆ¡n."
                                    )
                                elif score >= 60:
                                    st.warning(
                                        "ğŸ’ª KhÃ¡ á»•n! HÃ£y chÃº Ã½ cÃ¡c gÃ³p Ã½ phÃ­a dÆ°á»›i."
                                    )
                                else:
                                    st.error(
                                        "ğŸ“š Cáº§n cáº£i thiá»‡n. HÃ£y luyá»‡n táº­p thÃªm vá» phÃ¡t Ã¢m vÃ  Ä‘á»™ dÃ i bÃ i nÃ³i."
                                    )

                            # Feedback chi tiáº¿t
                            st.markdown("### ğŸ’¡ Pháº£n há»“i chi tiáº¿t")

                            # Hiá»ƒn thá»‹ feedback dáº¡ng markdown
                            feedback_text = "\n".join(feedback)
                            st.markdown(feedback_text)

                            # Gá»£i Ã½ luyá»‡n táº­p
                            with st.expander("ğŸ“– Gá»£i Ã½ cáº£i thiá»‡n cho tá»«ng tiÃªu chÃ­"):
                                st.markdown(
                                    """
                                **ğŸ—£ï¸ Pronunciation (PhÃ¡t Ã¢m):**
                                - Nghe vÃ  báº¯t chÆ°á»›c ngÆ°á»i báº£n ngá»¯ (BBC Learning English, VOA)
                                - Táº­p phÃ¡t Ã¢m cÃ¡c Ã¢m khÃ³: /Î¸/, /Ã°/, /r/, /l/
                                - Ghi Ã¢m vÃ  so sÃ¡nh vá»›i báº£n gá»‘c
                                
                                **ğŸµ Fluency (Äá»™ trÃ´i cháº£y):**
                                - Luyá»‡n nÃ³i khÃ´ng ngáº¯t quÃ£ng 1-2 phÃºt
                                - Giáº£m "uh", "um" báº±ng cÃ¡ch suy nghÄ© trÆ°á»›c khi nÃ³i
                                - Äá»c to 10-15 phÃºt má»—i ngÃ y
                                
                                **ğŸ“ Grammar (Ngá»¯ phÃ¡p):**
                                - Há»c thuá»™c cÃ¡c thÃ¬ cÆ¡ báº£n (hiá»‡n táº¡i, quÃ¡ khá»©, tÆ°Æ¡ng lai)
                                - ChÃº Ã½ Subject-Verb Agreement (I am, He is, They are)
                                - LÃ m bÃ i táº­p ngá»¯ phÃ¡p trÃªn app (Duolingo, Grammarly)
                                
                                **ğŸ“š Vocabulary (Tá»« vá»±ng):**
                                - Há»c 10 tá»« má»›i má»—i ngÃ y theo chá»§ Ä‘á»
                                - Sá»­ dá»¥ng tá»« vá»±ng Ä‘a dáº¡ng, trÃ¡nh láº·p láº¡i
                                - Äá»c sÃ¡ch/bÃ¡o tiáº¿ng Anh Ä‘á»ƒ má»Ÿ rá»™ng vá»‘n tá»«
                                
                                **ğŸ’¬ Communication (Giao tiáº¿p):**
                                - Tráº£ lá»i Ä‘áº§y Ä‘á»§ cÃ¢u há»i vá»›i lÃ½ do vÃ  vÃ­ dá»¥
                                - Sá»­ dá»¥ng tá»« ná»‘i: because, and, so, but
                                - Tá»• chá»©c Ã½: Introduction â†’ Main idea â†’ Example â†’ Conclusion
                                """
                                )

                        else:
                            st.error(
                                "âŒ KhÃ´ng thá»ƒ nháº­n dáº¡ng giá»ng nÃ³i. Vui lÃ²ng thá»­ láº¡i."
                            )
                    else:
                        st.error("âŒ KhÃ´ng thá»ƒ xá»­ lÃ½ file audio.")

                except Exception as e:
                    st.error(f"âŒ Lá»—i: {e}")

    # Hiá»ƒn thá»‹ lá»‹ch sá»­ gáº§n Ä‘Ã¢y
    if st.session_state.history:
        st.divider()
        st.subheader("ğŸ“œ Lá»‹ch sá»­ gáº§n Ä‘Ã¢y (5 láº§n cuá»‘i)")

        for item in reversed(st.session_state.history[-5:]):
            with st.expander(f"â° {item['timestamp']} - Äiá»ƒm: {item['score']}/100"):
                col_h1, col_h2 = st.columns(2)
                with col_h1:
                    st.write(f"**ğŸ“Œ Chá»§ Ä‘á»:** {item['reference']}")
                    st.write(f"**ğŸ—£ï¸ Ná»™i dung:** {item['transcribed'][:100]}...")
                with col_h2:
                    st.metric("Äiá»ƒm sá»‘", f"{item['score']}/100")
                    st.write(f"**ğŸ‘¤ NgÆ°á»i dÃ¹ng:** {item['user']}")
                    st.write(f"**ğŸ“ Sá»‘ tá»«:** {item['word_count']}")

                # Hiá»ƒn thá»‹ breakdown náº¿u cÃ³
                if "breakdown" in item and item["breakdown"]:
                    st.write("**ğŸ“Š Chi tiáº¿t Ä‘iá»ƒm:**")
                    breakdown = item["breakdown"]
                    col_b = st.columns(5)
                    labels = [
                        "Pronunciation",
                        "Fluency",
                        "Grammar",
                        "Vocabulary",
                        "Communication",
                    ]
                    for idx, label in enumerate(labels):
                        if label in breakdown:
                            with col_b[idx]:
                                st.metric(label[:6], f"{breakdown[label]:.1f}/2")

# TAB 2: THá»NG KÃŠ
with tab2:
    st.title("ğŸ“Š Thá»‘ng kÃª vÃ  PhÃ¢n tÃ­ch")

    stats = get_statistics()

    if stats and stats["total_attempts"] > 0:
        # Hiá»ƒn thá»‹ Streak
        streak = calculate_streak()
        if streak > 0:
            st.markdown(
                f"""
            <div class="streak-badge">
                ğŸ”¥ Streak: {streak} ngÃ y liÃªn tá»¥c!
            </div>
            """,
                unsafe_allow_html=True,
            )
            st.markdown("")

        # Tá»•ng quan
        st.subheader("ğŸ“ˆ Tá»•ng quan")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Tá»•ng sá»‘ láº§n phÃ¢n tÃ­ch", stats["total_attempts"])

        with col2:
            st.metric("Äiá»ƒm trung bÃ¬nh", f"{stats['avg_score']:.1f}/100")

        with col3:
            st.metric("Äiá»ƒm cao nháº¥t", f"{stats['max_score']}/100")

        with col4:
            st.metric("HÃ´m nay", f"{stats['today_attempts']} láº§n")

        st.divider()

        # Biá»ƒu Ä‘á»“
        col_chart1, col_chart2 = st.columns(2)

        with col_chart1:
            progress_chart = create_progress_chart()
            if progress_chart:
                st.plotly_chart(progress_chart, use_container_width=True)

        with col_chart2:
            dist_chart = create_score_distribution()
            if dist_chart:
                st.plotly_chart(dist_chart, use_container_width=True)

        st.divider()

        # Biá»ƒu Ä‘á»“ hoáº¡t Ä‘á»™ng 7 ngÃ y
        weekly_chart = create_weekly_chart()
        if weekly_chart:
            st.plotly_chart(weekly_chart, use_container_width=True)

        st.divider()

        # PhÃ¢n loáº¡i Ä‘iá»ƒm
        st.subheader("ğŸ¯ PhÃ¢n loáº¡i káº¿t quáº£")

        col_cat1, col_cat2, col_cat3, col_cat4 = st.columns(4)

        with col_cat1:
            st.markdown(
                f"""
            <div class="stat-box" style="border-left: 4px solid #00c853;">
                <h3>ğŸŸ¢ Xuáº¥t sáº¯c</h3>
                <h2>{stats['excellent_count']}</h2>
                <p>â‰¥ 90 Ä‘iá»ƒm</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col_cat2:
            st.markdown(
                f"""
            <div class="stat-box" style="border-left: 4px solid #ffd600;">
                <h3>ğŸŸ¡ KhÃ¡</h3>
                <h2>{stats['good_count']}</h2>
                <p>75-89 Ä‘iá»ƒm</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col_cat3:
            st.markdown(
                f"""
            <div class="stat-box" style="border-left: 4px solid #ff9800;">
                <h3>ğŸŸ  Trung bÃ¬nh</h3>
                <h2>{stats['average_count']}</h2>
                <p>60-74 Ä‘iá»ƒm</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col_cat4:
            st.markdown(
                f"""
            <div class="stat-box" style="border-left: 4px solid #ff5252;">
                <h3>ğŸ”´ Cáº§n cáº£i thiá»‡n</h3>
                <h2>{stats['poor_count']}</h2>
                <p>< 60 Ä‘iá»ƒm</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        st.divider()

        # Xuáº¥t bÃ¡o cÃ¡o
        st.subheader("ğŸ“¥ Xuáº¥t dá»¯ liá»‡u")

        col_export1, col_export2, col_export3 = st.columns(3)

        with col_export1:
            csv_data = export_history_to_csv()
            if csv_data:
                st.download_button(
                    label="ğŸ’¾ Táº£i CSV",
                    data=csv_data,
                    file_name=f"speech_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True,
                )

        with col_export2:
            json_data = export_history_to_json()
            if json_data:
                st.download_button(
                    label="ğŸ’¾ Táº£i JSON (Backup)",
                    data=json_data,
                    file_name=f"speech_analysis_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True,
                )

        with col_export3:
            if st.button("ğŸ—‘ï¸ XÃ³a lá»‹ch sá»­", use_container_width=True):
                if st.session_state.get("confirm_delete", False):
                    st.session_state.history = []
                    st.session_state.confirm_delete = False
                    st.rerun()
                else:
                    st.session_state.confirm_delete = True
                    st.warning("âš ï¸ Nháº¥n láº§n ná»¯a Ä‘á»ƒ xÃ¡c nháº­n!")

    else:
        st.info("ğŸ“Š ChÆ°a cÃ³ dá»¯ liá»‡u thá»‘ng kÃª. HÃ£y báº¯t Ä‘áº§u phÃ¢n tÃ­ch bÃ i nÃ³i Ä‘áº§u tiÃªn!")

# TAB 3: CÃ€I Äáº¶T
with tab3:
    st.title("âš™ï¸ CÃ i Ä‘áº·t")

    # ThÃ´ng tin ngÆ°á»i dÃ¹ng
    st.subheader("ğŸ‘¤ ThÃ´ng tin ngÆ°á»i dÃ¹ng")
    user_name = st.text_input("TÃªn cá»§a báº¡n:", value=st.session_state.user_name)

    if user_name != st.session_state.user_name:
        st.session_state.user_name = user_name
        st.success("âœ… ÄÃ£ lÆ°u tÃªn!")

    st.divider()

    # CÃ i Ä‘áº·t má»¥c tiÃªu
    st.subheader("ğŸ¯ Má»¥c tiÃªu luyá»‡n táº­p")
    daily_goal = st.slider(
        "Sá»‘ láº§n phÃ¢n tÃ­ch má»—i ngÃ y:",
        min_value=1,
        max_value=50,
        value=st.session_state.daily_goal,
        help="Äáº·t má»¥c tiÃªu sá»‘ láº§n phÃ¢n tÃ­ch bÃ i nÃ³i hÃ ng ngÃ y",
    )

    if daily_goal != st.session_state.daily_goal:
        st.session_state.daily_goal = daily_goal
        st.success(f"âœ… ÄÃ£ Ä‘áº·t má»¥c tiÃªu: {daily_goal} láº§n/ngÃ y")

    st.divider()

    # CÃ i Ä‘áº·t Model Whisper
    st.subheader("ğŸ¤– MÃ´ hÃ¬nh AI")

    col_model1, col_model2 = st.columns(2)

    with col_model1:
        model_size = st.selectbox(
            "Chá»n mÃ´ hÃ¬nh Whisper:",
            options=["tiny", "base", "small"],
            index=["tiny", "base", "small"].index(st.session_state.model_size),
            help="""
            - tiny: Nhanh nháº¥t, Ä‘á»™ chÃ­nh xÃ¡c tháº¥p nháº¥t (39MB)
            - base: CÃ¢n báº±ng tá»‘c Ä‘á»™ vÃ  Ä‘á»™ chÃ­nh xÃ¡c (74MB) - Khuyáº¿n nghá»‹
            - small: Cháº­m hÆ¡n nhÆ°ng chÃ­nh xÃ¡c hÆ¡n (244MB)
            """,
        )

    with col_model2:
        if st.session_state.model is not None:
            st.success(f"Model Ä‘ang dÃ¹ng: **{st.session_state.model_size}**")
        else:
            st.warning("ChÆ°a load model")

    if st.button("Load/Reload Model", type="primary", use_container_width=True):
        with st.spinner(f"Äang táº£i model {model_size}..."):
            model = load_whisper_model(model_size)
            if model:
                st.session_state.model = model
                st.session_state.model_size = model_size
                st.success(f"âœ… ÄÃ£ load model {model_size} thÃ nh cÃ´ng!")
                st.balloons()
            else:
                st.error("âŒ KhÃ´ng thá»ƒ load model. Vui lÃ²ng thá»­ láº¡i.")

    st.divider()

    # Import/Export dá»¯ liá»‡u
    st.subheader("ğŸ’¾ Sao lÆ°u & KhÃ´i phá»¥c")

    col_backup1, col_backup2 = st.columns(2)

    with col_backup1:
        st.markdown("**Xuáº¥t dá»¯ liá»‡u (Backup)**")
        json_backup = export_history_to_json()
        if json_backup:
            st.download_button(
                label="ğŸ“¥ Táº£i file backup (JSON)",
                data=json_backup,
                file_name=f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True,
            )
        else:
            st.info("ChÆ°a cÃ³ dá»¯ liá»‡u Ä‘á»ƒ backup")

    with col_backup2:
        st.markdown("**Nháº­p dá»¯ liá»‡u (Restore)**")
        upload_backup = st.file_uploader(
            "Chá»n file backup JSON:",
            type=["json"],
            help="Upload file JSON Ä‘Ã£ backup trÆ°á»›c Ä‘Ã³",
        )

        if upload_backup:
            if st.button("ğŸ“¤ KhÃ´i phá»¥c dá»¯ liá»‡u", use_container_width=True):
                if import_history_from_json(upload_backup):
                    st.success("âœ… ÄÃ£ khÃ´i phá»¥c dá»¯ liá»‡u thÃ nh cÃ´ng!")
                    st.rerun()
                else:
                    st.error("âŒ KhÃ´ng thá»ƒ khÃ´i phá»¥c. File khÃ´ng há»£p lá»‡.")

    st.divider()

    # ThÃ´ng tin á»©ng dá»¥ng
    st.subheader("â„¹ï¸ ThÃ´ng tin á»©ng dá»¥ng")

    st.info(
        """
    **ğŸ¤ á»¨ng dá»¥ng PhÃ¢n tÃ­ch PhÃ¡t Ã‚m BÃ i NÃ³i Tá»± Do**
    
    **PhiÃªn báº£n:** 3.1 - Enhanced Pronunciation Feedback
    
    **TÃ­nh nÄƒng chÃ­nh:**
    - PhÃ¢n tÃ­ch phÃ¡t Ã¢m tá»± Ä‘á»™ng vá»›i AI (Whisper)
    - Cháº¥m Ä‘iá»ƒm theo 5 tiÃªu chÃ­ vá»›i pháº£n há»“i chi tiáº¿t
    - PhÃ¡t hiá»‡n tá»« phÃ¡t Ã¢m sai vÃ  Ä‘Æ°a ra gá»£i Ã½ sá»­a
    - Thá»‘ng kÃª chi tiáº¿t vÃ  biá»ƒu Ä‘á»“ trá»±c quan
    - Theo dÃµi streak vÃ  má»¥c tiÃªu hÃ ng ngÃ y
    - Sao lÆ°u/khÃ´i phá»¥c dá»¯ liá»‡u
    
    **CÃ´ng nghá»‡:**
    - Streamlit
    - OpenAI Whisper (ASR)
    - Plotly Charts
    - Advanced NLP Analysis
    
    **Thang Ä‘iá»ƒm:**
    - Pronunciation: Äá»™ rÃµ rÃ ng, chÃ­nh xÃ¡c phÃ¡t Ã¢m (/2)
    - Fluency: Äá»™ trÃ´i cháº£y, tá»± nhiÃªn (/2)
    - Grammar: Ngá»¯ phÃ¡p chÃ­nh xÃ¡c (/2)
    - Vocabulary: Tá»« vá»±ng Ä‘a dáº¡ng (/2)
    - Communication: Truyá»n Ä‘áº¡t Ã½ rÃµ rÃ ng (/2)
    - Tá»•ng: /10 Ä‘iá»ƒm (tÆ°Æ¡ng Ä‘Æ°Æ¡ng /100)
    """
    )

    st.divider()

    # NÃºt reset toÃ n bá»™
    st.subheader("ğŸš¨ Zone Nguy hiá»ƒm")

    if st.button("ğŸ—‘ï¸ XÃ³a toÃ n bá»™ dá»¯ liá»‡u vÃ  cÃ i Ä‘áº·t", type="secondary"):
        if st.session_state.get("confirm_reset_all", False):
            st.session_state.history = []
            st.session_state.user_name = "Há»c viÃªn"
            st.session_state.daily_goal = 10
            st.session_state.confirm_reset_all = False
            st.success("âœ… ÄÃ£ reset toÃ n bá»™!")
            st.rerun()
        else:
            st.session_state.confirm_reset_all = True
            st.error(
                "âš ï¸ Cáº¢NH BÃO: Báº¡n sáº½ máº¥t toÃ n bá»™ dá»¯ liá»‡u! Nháº¥n láº§n ná»¯a Ä‘á»ƒ xÃ¡c nháº­n."
            )

# Footer
st.divider()
st.markdown(
    """
<style>
.footer-link {
    color: gray;
    text-decoration: none;
    transition: color 0.3s ease;
}
.footer-link:hover {
    color: #1f77b4;
}
</style>

<div style='text-align: center; color: gray; padding: 16px 0; font-size: 14px;'>
    <p><strong>á»¨ng dá»¥ng PhÃ¢n tÃ­ch PhÃ¡t Ã‚m BÃ i NÃ³i Tá»± Do</strong></p>
    <p>Miá»…n phÃ­ â€¢ Offline/Online â€¢ KhÃ´ng dÃ¹ng API tráº£ phÃ­</p>
    <p>Sá»­ dá»¥ng: Whisper (OpenAI) + Streamlit + Enhanced Pronunciation Analysis</p>
    <p style='margin-top:10px;'>Â© 2025 
        <a href='https://www.facebook.com/augusttrung1823/' target='_blank' class='footer-link'>
            August Trung
        </a>. All rights reserved.
    </p>
</div>
""",
    unsafe_allow_html=True,
)
